{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Burning Man Events Data: Predicting Probabilities\n",
    "\n",
    "In the previous classification approach we considered events to be exclusive a single type, with Precision, Recall, and F1 score as classification metrics. But, this may not necessarily be the case in practice. An event could be both a party and a food event for example. This possibility was made more evident upon analyzing the types of errors being made by the classifiers. Certain types of mislabels were common.\n",
    "\n",
    "Alternatively, we can instead predict the non-exclusive probability that event be categorized into a given type, and use a metric like ROC-AUC to gauge classifier performance.\n",
    "\n",
    "We'll start off the same as before, establishing baselines one step at a time. Totally random, or even weighted random, guessing gives a ROC-AUC of 0.5, corresponding to useful distinction between positive and negative labels. A simple rule-based system, just like the one used previously, but this time allowing for multiple positives, gives an average ROC-AUC of 0.65 with a standard deviation of 0.08. A noticable improvement. Adding more compex features along with logistic regression improves the ROC-AUC up to almost 0.80. And including word vectors brings this up even higher towards 0.87! A 0-1 prediction mechanism on the other hand only gives a ROC-AUC of 0.65.\n",
    "\n",
    "tl;dr Burning Man Org should consider allowing events to have multiple labels\n",
    "\n",
    "- <a href='#total'> Totally Random Guessing </a>\n",
    "- <a href='#simple'> Simple Rule Based Classification </a>\n",
    "- <a href='#complex'> More Complex Engineered Features </a>\n",
    "- <a href='#statsmodels'> Feature Importance with StatsModels </a>\n",
    "- <a href='#tfidf'> With TF-IDF Features </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import seaborn as sns;\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "import string, nltk, re, pprint\n",
    "\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "from pylab import *;\n",
    "from scipy import sparse\n",
    "from time import time\n",
    "\n",
    "from nltk.corpus   import stopwords\n",
    "from nltk          import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error, mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import lightgbm as lgb;\n",
    "\n",
    "import random\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import statsmodels.discrete.discrete_model as dm\n",
    "# workaround for a statsmodels problem missing chi2\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv('raw_data/cleaned_up.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types_test = pd.get_dummies(events['Type'])\n",
    "\n",
    "events = events.drop(['Type'], axis=1)\n",
    "\n",
    "type_names = types_test.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='total'></a> \n",
    "\n",
    "# Totally Random Guessing\n",
    "\n",
    "Random guessing gives a ROC-AUC score of 0.5, corresponding to no seperation between positive/negative predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 20165/20165 [00:45<00:00, 440.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adult-oriented</th>\n",
       "      <th>Care/Support</th>\n",
       "      <th>Class/Workshop</th>\n",
       "      <th>Fire</th>\n",
       "      <th>Food</th>\n",
       "      <th>Game</th>\n",
       "      <th>Gathering/Party</th>\n",
       "      <th>Kid-friendly</th>\n",
       "      <th>Other</th>\n",
       "      <th>Parade</th>\n",
       "      <th>Performance</th>\n",
       "      <th>Ritual/Ceremony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.975835</td>\n",
       "      <td>0.390713</td>\n",
       "      <td>0.106307</td>\n",
       "      <td>0.341328</td>\n",
       "      <td>0.559250</td>\n",
       "      <td>0.500633</td>\n",
       "      <td>0.396881</td>\n",
       "      <td>0.407683</td>\n",
       "      <td>0.877327</td>\n",
       "      <td>0.552137</td>\n",
       "      <td>0.315615</td>\n",
       "      <td>0.230538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.627725</td>\n",
       "      <td>0.573499</td>\n",
       "      <td>0.580961</td>\n",
       "      <td>0.848518</td>\n",
       "      <td>0.077781</td>\n",
       "      <td>0.702374</td>\n",
       "      <td>0.112620</td>\n",
       "      <td>0.066988</td>\n",
       "      <td>0.107543</td>\n",
       "      <td>0.983907</td>\n",
       "      <td>0.814209</td>\n",
       "      <td>0.857691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.635816</td>\n",
       "      <td>0.031868</td>\n",
       "      <td>0.506356</td>\n",
       "      <td>0.924487</td>\n",
       "      <td>0.898475</td>\n",
       "      <td>0.656403</td>\n",
       "      <td>0.907343</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.614324</td>\n",
       "      <td>0.807869</td>\n",
       "      <td>0.392421</td>\n",
       "      <td>0.855286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.541222</td>\n",
       "      <td>0.417662</td>\n",
       "      <td>0.961777</td>\n",
       "      <td>0.931613</td>\n",
       "      <td>0.673746</td>\n",
       "      <td>0.293533</td>\n",
       "      <td>0.974955</td>\n",
       "      <td>0.373940</td>\n",
       "      <td>0.938506</td>\n",
       "      <td>0.801623</td>\n",
       "      <td>0.644234</td>\n",
       "      <td>0.494834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100472</td>\n",
       "      <td>0.877497</td>\n",
       "      <td>0.411177</td>\n",
       "      <td>0.883322</td>\n",
       "      <td>0.105490</td>\n",
       "      <td>0.107107</td>\n",
       "      <td>0.555637</td>\n",
       "      <td>0.733455</td>\n",
       "      <td>0.121749</td>\n",
       "      <td>0.675545</td>\n",
       "      <td>0.054966</td>\n",
       "      <td>0.217408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adult-oriented  Care/Support  Class/Workshop      Fire      Food      Game  \\\n",
       "0        0.975835      0.390713        0.106307  0.341328  0.559250  0.500633   \n",
       "1        0.627725      0.573499        0.580961  0.848518  0.077781  0.702374   \n",
       "2        0.635816      0.031868        0.506356  0.924487  0.898475  0.656403   \n",
       "3        0.541222      0.417662        0.961777  0.931613  0.673746  0.293533   \n",
       "4        0.100472      0.877497        0.411177  0.883322  0.105490  0.107107   \n",
       "\n",
       "   Gathering/Party  Kid-friendly     Other    Parade  Performance  \\\n",
       "0         0.396881      0.407683  0.877327  0.552137     0.315615   \n",
       "1         0.112620      0.066988  0.107543  0.983907     0.814209   \n",
       "2         0.907343      0.069315  0.614324  0.807869     0.392421   \n",
       "3         0.974955      0.373940  0.938506  0.801623     0.644234   \n",
       "4         0.555637      0.733455  0.121749  0.675545     0.054966   \n",
       "\n",
       "   Ritual/Ceremony  \n",
       "0         0.230538  \n",
       "1         0.857691  \n",
       "2         0.855286  \n",
       "3         0.494834  \n",
       "4         0.217408  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_pred = pd.DataFrame(columns=type_names)\n",
    "\n",
    "for i in tqdm(range(len(types_test))):\n",
    "    types_pred = types_pred.append({name:random.uniform(0, 1) for name in type_names}, ignore_index=True)\n",
    "\n",
    "types_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.49593694351676354\n",
      "Std Dev ROC-AUC: 0.008949933671384422\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(types_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighed by prior event distributions, the average ROC-AUC is exactly 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 20165/20165 [00:44<00:00, 450.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adult-oriented</th>\n",
       "      <th>Care/Support</th>\n",
       "      <th>Class/Workshop</th>\n",
       "      <th>Fire</th>\n",
       "      <th>Food</th>\n",
       "      <th>Game</th>\n",
       "      <th>Gathering/Party</th>\n",
       "      <th>Kid-friendly</th>\n",
       "      <th>Other</th>\n",
       "      <th>Parade</th>\n",
       "      <th>Performance</th>\n",
       "      <th>Ritual/Ceremony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05574</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.318324</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.041557</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.261939</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.070469</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.077213</td>\n",
       "      <td>0.05088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05574</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.318324</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.041557</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.261939</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.070469</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.077213</td>\n",
       "      <td>0.05088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05574</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.318324</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.041557</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.261939</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.070469</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.077213</td>\n",
       "      <td>0.05088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05574</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.318324</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.041557</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.261939</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.070469</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.077213</td>\n",
       "      <td>0.05088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05574</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.318324</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.041557</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.261939</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.070469</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.077213</td>\n",
       "      <td>0.05088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adult-oriented  Care/Support  Class/Workshop      Fire      Food      Game  \\\n",
       "0         0.05574      0.036896        0.318324  0.008034  0.041557  0.047012   \n",
       "1         0.05574      0.036896        0.318324  0.008034  0.041557  0.047012   \n",
       "2         0.05574      0.036896        0.318324  0.008034  0.041557  0.047012   \n",
       "3         0.05574      0.036896        0.318324  0.008034  0.041557  0.047012   \n",
       "4         0.05574      0.036896        0.318324  0.008034  0.041557  0.047012   \n",
       "\n",
       "   Gathering/Party  Kid-friendly     Other    Parade  Performance  \\\n",
       "0         0.261939      0.018001  0.070469  0.013935     0.077213   \n",
       "1         0.261939      0.018001  0.070469  0.013935     0.077213   \n",
       "2         0.261939      0.018001  0.070469  0.013935     0.077213   \n",
       "3         0.261939      0.018001  0.070469  0.013935     0.077213   \n",
       "4         0.261939      0.018001  0.070469  0.013935     0.077213   \n",
       "\n",
       "   Ritual/Ceremony  \n",
       "0          0.05088  \n",
       "1          0.05088  \n",
       "2          0.05088  \n",
       "3          0.05088  \n",
       "4          0.05088  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_pred = pd.DataFrame(columns=type_names)\n",
    "\n",
    "p = types_test.sum().values/types_test.sum().values.sum()\n",
    "\n",
    "for i in tqdm(range(len(types_test))):\n",
    "    types_pred = types_pred.append({name:p[i] for i, name in enumerate(type_names)}, ignore_index=True)\n",
    "\n",
    "types_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.5\n",
      "Std Dev ROC-AUC: 0.0\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(types_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='simple'></a>\n",
    "\n",
    "# Simple Rule-Based Classification\n",
    "\n",
    "Let's see what accuracy we can achieve using an extremely simple rule-based classification scheme, based on findings from the Exploratory Data Analysis.\n",
    "\n",
    "This simple rule system brings the ROC-AUC up to 0.65, with a standard-deviation of 0.08. So we did get a noticable improvement over random guessing with this sytem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events[\"Description\"] = (events[\"Description\"].map(str) + ' ' + \n",
    "                         events[\"Title\"].map(str) + ' ' + \n",
    "                         events[\"Hosted by Camp\"].map(str) + ' ' + \n",
    "                         events[\"Location\"].map(str))\n",
    "\n",
    "events = events.drop(['Title', 'Hosted by Camp', 'Location'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_words  = ['adult', 'massage', 'sensual', 'erotic', 'sex', 'bdsm', 'pleasure']\n",
    "care_words   = ['heal', 'massage', 'help', 'body']\n",
    "class_words  = ['learn', 'workshop', 'practice', 'class']\n",
    "fire_words   = ['fire', 'burn', 'spin', 'fuel', 'flame', 'light', 'flow']\n",
    "food_words   = ['coffee', 'pickle', 'food', 'serv', 'fresh', 'bacon', 'cheese', 'delicious', 'pancake', 'tast']\n",
    "game_words   = ['game', 'play', 'prize', 'race', 'tournament']\n",
    "party_words  = ['party', 'dance', 'music', 'celebrate']\n",
    "kids_words   = ['kid', 'scout']\n",
    "parade_words = ['parade', 'march', 'tour']\n",
    "perfor_words = ['perform', 'stage', 'live', 'show', 'audience']\n",
    "ritual_words = ['ceremony', 'ritual', 'temple', 'sacred']\n",
    "\n",
    "words = {'Adult-oriented': adult_words,\n",
    "         'Care/Support':care_words,\n",
    "         'Class/Workshop':class_words,\n",
    "         'Fire':fire_words,\n",
    "         'Food':food_words,\n",
    "         'Game':game_words,\n",
    "         'Gathering/Party':party_words,\n",
    "         'Kid-friendly':kids_words,\n",
    "         'Parade':parade_words,\n",
    "         'Performance':perfor_words,\n",
    "         'Ritual/Ceremony':ritual_words,\n",
    "         'Other':[]}\n",
    "\n",
    "def simple_classify(desc, words):\n",
    "    return any([word in desc for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 20165/20165 [01:16<00:00, 261.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adult-oriented</th>\n",
       "      <th>Care/Support</th>\n",
       "      <th>Class/Workshop</th>\n",
       "      <th>Fire</th>\n",
       "      <th>Food</th>\n",
       "      <th>Game</th>\n",
       "      <th>Gathering/Party</th>\n",
       "      <th>Kid-friendly</th>\n",
       "      <th>Other</th>\n",
       "      <th>Parade</th>\n",
       "      <th>Performance</th>\n",
       "      <th>Ritual/Ceremony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Adult-oriented Care/Support Class/Workshop   Fire   Food   Game  \\\n",
       "0          False        False          False   True  False  False   \n",
       "1          False        False          False  False  False  False   \n",
       "2          False        False          False  False  False  False   \n",
       "3          False        False          False  False  False  False   \n",
       "4          False        False          False  False  False  False   \n",
       "\n",
       "  Gathering/Party Kid-friendly  Other Parade Performance Ritual/Ceremony  \n",
       "0           False        False  False  False       False           False  \n",
       "1           False        False  False  False       False           False  \n",
       "2           False        False  False  False       False           False  \n",
       "3           False        False  False  False       False           False  \n",
       "4           False        False  False  False       False           False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_pred = pd.DataFrame(columns=type_names)\n",
    "\n",
    "descriptions = events['Description'].values\n",
    "\n",
    "for desc in tqdm(descriptions):\n",
    "    types_pred = types_pred.append({name:simple_classify(desc, words[name]) for name in type_names}, ignore_index=True)\n",
    "        \n",
    "types_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.6527309204301003\n",
      "Std Dev ROC-AUC: 0.08677021943808555\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(types_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='complex'></a>\n",
    "\n",
    "# More Complex Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 720549.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 153658.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 124124.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 106250.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 105247.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 133565.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 236681.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 330605.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 694966.68it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_12_to_24(time):\n",
    "    if 'a.m.' in time:\n",
    "        time = time.replace(' a.m.', '')\n",
    "        if ':' not in time:\n",
    "            time = time + ':00'    \n",
    "    elif 'p.m.' in time:\n",
    "        time = time.replace(' p.m.', '')\n",
    "        if ':' not in time:\n",
    "            if '12' in time:\n",
    "                time = time + ':00'\n",
    "            else:\n",
    "                time = str(int(time)+12) + ':00'\n",
    "        elif '12' in time:\n",
    "            pass\n",
    "        else:\n",
    "            time_split = time.split(':')\n",
    "            time = str(int(time_split[0])+12) + ':' + time_split[1]\n",
    "    elif 'midnight' in time:\n",
    "        time = '23:45'\n",
    "    elif 'noon' in time:\n",
    "        time = '12:00'\n",
    "            \n",
    "    return time\n",
    "\n",
    "def get_time_diff(df):      \n",
    "    times = [];\n",
    "\n",
    "    for row in tqdm(df.values): \n",
    "        if row == '0':\n",
    "            times.append(np.nan);\n",
    "        elif row == 'All Day':\n",
    "            times.append((datetime.datetime.strptime('23:59', '%H:%M')-datetime.datetime.strptime('00:00', '%H:%M')).total_seconds()/3600)\n",
    "        else:\n",
    "            split = row.split(' – ');\n",
    "            \n",
    "            split[0] = convert_12_to_24(split[0])\n",
    "            split[1] = convert_12_to_24(split[1])\n",
    "\n",
    "            times.append((datetime.datetime.strptime(split[1], '%H:%M')-datetime.datetime.strptime(split[0], '%H:%M')).total_seconds()/3600)\n",
    "    \n",
    "    return times;\n",
    "\n",
    "times_1 = pd.DataFrame(get_time_diff(events['Sunday']),    columns=['Event Length'])\n",
    "times_2 = pd.DataFrame(get_time_diff(events['Monday']),    columns=['Event Length'])\n",
    "times_3 = pd.DataFrame(get_time_diff(events['Tuesday']),   columns=['Event Length'])\n",
    "times_4 = pd.DataFrame(get_time_diff(events['Wednesday']), columns=['Event Length'])\n",
    "times_5 = pd.DataFrame(get_time_diff(events['Thursday']),  columns=['Event Length'])\n",
    "times_6 = pd.DataFrame(get_time_diff(events['Friday']),    columns=['Event Length'])\n",
    "times_7 = pd.DataFrame(get_time_diff(events['Saturday']),  columns=['Event Length'])\n",
    "times_8 = pd.DataFrame(get_time_diff(events['Sunday2']),   columns=['Event Length'])\n",
    "times_9 = pd.DataFrame(get_time_diff(events['Monday2']),   columns=['Event Length'])\n",
    "\n",
    "times = times_1.fillna(times_2).fillna(times_3).fillna(times_4).fillna(times_5).fillna(times_6).fillna(times_7).fillna(times_8).fillna(times_9)\n",
    "\n",
    "events['Event Length'] = abs(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert Days to Simple Binary (Lose Time of Day Information)\n",
    "\n",
    "days = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday2', 'Monday2'];\n",
    "\n",
    "events[days] = ((events[days] == '0') == False).astype(int);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events['Times Repeated'] = 0\n",
    "\n",
    "for day in days:\n",
    "    events['Times Repeated'] += events[day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert Contact Email, URL to Binary\n",
    "\n",
    "events['Contact Email']  = pd.isnull(events['Contact Email']).values.astype(int)\n",
    "events['URL']            = pd.isnull(events['URL']).values.astype(int)\n",
    "events['Located at Art'] = pd.isnull(events['Located at Art']).values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first build a classifier with simple engineered features (no TF-IDF) and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# FEATURE ENGINEERING #\n",
    "#######################\n",
    "\n",
    "def engineer_feature(series, func, normalize=True):\n",
    "    feature = series.apply(func)   \n",
    "    if normalize:\n",
    "        feature = pd.Series(z_normalize(feature.values.reshape(-1,1)).reshape(-1,))\n",
    "    feature.name = func.__name__ \n",
    "    return feature\n",
    "def engineer_features(series, funclist, normalize=True):\n",
    "    features = pd.DataFrame()\n",
    "    for func in funclist:\n",
    "        print(str(func))\n",
    "        feature = engineer_feature(series, func, normalize)\n",
    "        features[feature.name] = feature\n",
    "    return features\n",
    "\n",
    "##################\n",
    "### Normalizer ###\n",
    "##################\n",
    "\n",
    "scaler = StandardScaler()\n",
    "def z_normalize(data):\n",
    "    scaler.fit(data)\n",
    "    return scaler.transform(data)   \n",
    "def count_words(x, words):\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        count += len(re.findall(word, str(x)))\n",
    "    return count\n",
    "    \n",
    "################\n",
    "### Features ###\n",
    "################\n",
    "\n",
    "def uppercase_freq(x):\n",
    "    return len(re.findall(r'[A-Z]', x))/len(x)\n",
    "def sentence_count(x):\n",
    "    return len(re.findall(\"\\n\", str(x)))+1\n",
    "def word_count(x):\n",
    "    return len(str(x).split())\n",
    "def unique_word_count(x):\n",
    "    return len(set(str(x).split()))\n",
    "def count_letters(x):\n",
    "    return len(str(x))\n",
    "def count_punctuations(x):\n",
    "    return len([c for c in str(x) if c in string.punctuation])\n",
    "def count_words_title(x):\n",
    "    return len([w for w in str(x).split() if w.istitle()])\n",
    "def count_stopwords(x):\n",
    "    return len([w for w in str(x).lower().split() if w in eng_stopwords])\n",
    "def mean_word_len(x):\n",
    "    words = [len(w) for w in str(x).split()]\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.mean(words)\n",
    "\n",
    "##################################\n",
    "### Category-Specific Features ###\n",
    "##################################\n",
    "\n",
    "def count_kids_words(x):\n",
    "    return count_words(x, ['kid', 'scout'])\n",
    "def count_party_words(x):\n",
    "    return count_words(x, ['party', 'dance', 'music', 'celebrate'])\n",
    "def count_adult_words(x):\n",
    "    return count_words(x, ['adult', 'massage', 'sensual', 'erotic', 'sex', 'bdsm', 'pleasure'])\n",
    "def count_game_words(x):\n",
    "    return count_words(x, ['game', 'play', 'prize', 'race', 'tournament'])\n",
    "def count_ritual_words(x):\n",
    "    return count_words(x, ['ceremony', 'ritual', 'temple', 'sacred']) \n",
    "def count_care_words(x):\n",
    "    return count_words(x, ['heal', 'massage', 'help', 'body'])\n",
    "def count_class_words(x):\n",
    "    return count_words(x, ['learn', 'workshop', 'practice', 'class'])\n",
    "def count_performance_words(x):\n",
    "    return count_words(x, ['perform', 'stage', 'live', 'show', 'audience'])\n",
    "def count_food_words(x):\n",
    "    return count_words(x, ['coffee', 'pickle', 'food', 'serv', 'fresh', 'bacon', 'cheese', 'delicious', 'pancake', 'tast'])\n",
    "def count_fire_words(x):\n",
    "    return count_words(x, ['fire', 'burn', 'spin', 'fuel', 'flame', 'light', 'flow'])\n",
    "def count_parade_words(x):\n",
    "    return count_words(x, ['parade', 'march', 'tour'])\n",
    "\n",
    "############################\n",
    "### Sentimental Features ###\n",
    "############################\n",
    "\n",
    "sia = SIA();\n",
    "def sentiment_compound(x):\n",
    "    polarity = sia.polarity_scores(x)\n",
    "    return polarity['compound']       \n",
    "def sentiment_negative(x):\n",
    "    polarity = sia.polarity_scores(x)\n",
    "    return polarity['neg']       \n",
    "def sentiment_neutral(x):\n",
    "    polarity = sia.polarity_scores(x)\n",
    "    return polarity['neu']       \n",
    "def sentiment_positive(x):\n",
    "    polarity = sia.polarity_scores(x)\n",
    "    return polarity['pos']       \n",
    "        \n",
    "########################\n",
    "### Derived Features ###\n",
    "########################\n",
    "\n",
    "def unique_word_ratio(x):\n",
    "    wc = word_count(x)   \n",
    "    if wc == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return unique_word_count(x)/wc\n",
    "def percent_ratio(x):\n",
    "    wc = word_count(x)\n",
    "    if wc == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return count_punctuations(x)/wc\n",
    "def words_per_sentence(x):\n",
    "    sc = sentence_count(x)\n",
    "    if sc == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return word_count(x)/sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function uppercase_freq at 0x0000024CA7ACCC80>\n",
      "<function sentence_count at 0x0000024CA7ACC0D0>\n",
      "<function word_count at 0x0000024CA7ACC2F0>\n",
      "<function unique_word_count at 0x0000024CA7ACC378>\n",
      "<function count_letters at 0x0000024CA7ACC510>\n",
      "<function count_punctuations at 0x0000024CA7ACC400>\n",
      "<function count_words_title at 0x0000024CA7ACC488>\n",
      "<function count_stopwords at 0x0000024CA7ACC8C8>\n",
      "<function mean_word_len at 0x0000024CA7ACCBF8>\n",
      "<function count_kids_words at 0x0000024CA7BD31E0>\n",
      "<function count_party_words at 0x0000024CA7BD3048>\n",
      "<function count_adult_words at 0x0000024CA7BD30D0>\n",
      "<function count_game_words at 0x0000024CA7BD32F0>\n",
      "<function count_ritual_words at 0x0000024CA79F1840>\n",
      "<function count_care_words at 0x0000024CA79F1488>\n",
      "<function count_class_words at 0x0000024CA79F17B8>\n",
      "<function count_performance_words at 0x0000024CA79F1158>\n",
      "<function count_food_words at 0x0000024CA79F1F28>\n",
      "<function count_fire_words at 0x0000024CA79F1EA0>\n",
      "<function count_parade_words at 0x0000024CA79F1E18>\n",
      "<function unique_word_ratio at 0x0000024CA79F1A60>\n",
      "<function percent_ratio at 0x0000024CA79F11E0>\n",
      "<function words_per_sentence at 0x0000024CA79F12F0>\n",
      "<function sentiment_compound at 0x0000024CF9370158>\n",
      "<function sentiment_negative at 0x0000024CA79F1D90>\n",
      "<function sentiment_positive at 0x0000024CA79F1620>\n",
      "<function sentiment_neutral at 0x0000024CA79F1C80>\n"
     ]
    }
   ],
   "source": [
    "feature_functions = [uppercase_freq, sentence_count, word_count, unique_word_count, count_letters, count_punctuations, \n",
    "                     count_words_title, count_stopwords, mean_word_len, count_kids_words, count_party_words, \n",
    "                     count_adult_words, count_game_words, count_ritual_words, count_care_words,\n",
    "                     count_class_words, count_performance_words, count_food_words, count_fire_words, count_parade_words,\n",
    "                     unique_word_ratio, percent_ratio, words_per_sentence,\n",
    "                     sentiment_compound, sentiment_negative, sentiment_positive, sentiment_neutral]\n",
    "\n",
    "features = [f.__name__ for f in feature_functions]\n",
    "\n",
    "F_train = engineer_features(events['Description'].fillna(''), feature_functions, normalize=False)\n",
    "\n",
    "X_handFeatures = F_train[features].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20165, 40)\n"
     ]
    }
   ],
   "source": [
    "basic_features = ['Contact Email', 'URL', 'Located at Art', 'Event Length']\n",
    "\n",
    "X = sparse.csr_matrix(hstack((X_handFeatures, events[days].values, events[basic_features].values)))\n",
    "\n",
    "print(shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adult-oriented</th>\n",
       "      <th>Care/Support</th>\n",
       "      <th>Class/Workshop</th>\n",
       "      <th>Fire</th>\n",
       "      <th>Food</th>\n",
       "      <th>Game</th>\n",
       "      <th>Gathering/Party</th>\n",
       "      <th>Kid-friendly</th>\n",
       "      <th>Other</th>\n",
       "      <th>Parade</th>\n",
       "      <th>Performance</th>\n",
       "      <th>Ritual/Ceremony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adult-oriented  Care/Support  Class/Workshop  Fire  Food  Game  \\\n",
       "0               0             0               0     0     0     0   \n",
       "1               0             0               0     0     0     0   \n",
       "2               0             0               0     0     0     0   \n",
       "3               0             0               0     0     0     0   \n",
       "4               0             0               0     0     0     1   \n",
       "\n",
       "   Gathering/Party  Kid-friendly  Other  Parade  Performance  Ritual/Ceremony  \n",
       "0                0             0      1       0            0                0  \n",
       "1                0             1      0       0            0                0  \n",
       "2                0             1      0       0            0                0  \n",
       "3                1             0      0       0            0                0  \n",
       "4                0             0      0       0            0                0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10082, 40)\n",
      "(10083, 40)\n",
      "(10082, 12)\n",
      "(10083, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, types_test, test_size=0.5, stratify=types_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting 0,1 probablities give an ROC-AUC only a little better than random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.92it/s]\n"
     ]
    }
   ],
   "source": [
    "types_pred = y_test.copy()\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for name in tqdm(type_names):\n",
    "    clf = LogisticRegression().fit(X_train, y_train[name])\n",
    "    \n",
    "    types_pred[name] = clf.predict(X_test)\n",
    "    \n",
    "    classifiers.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.5627325728279179\n",
      "Std Dev ROC-AUC: 0.05981430712187226\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(y_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas predicting the probabilities of each class shoots the average ROC-AUC all the way up to almost 0.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.90it/s]\n"
     ]
    }
   ],
   "source": [
    "types_pred = y_test.copy()\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for name in tqdm(type_names):\n",
    "    clf = LogisticRegression().fit(X_train, y_train[name])\n",
    "    \n",
    "    types_pred[name] = 1-clf.predict_proba(X_test) # not sure why sklearn is outputting the wrong (1-p) probability\n",
    "    \n",
    "    classifiers.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.7951847309055863\n",
      "Std Dev ROC-AUC: 0.06622114708620694\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(y_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='statsmodels'></a>\n",
    "\n",
    "# Assessing Feature Importance with StatsModels\n",
    "\n",
    "We can use the StatsModels package to analyze the relative importance of the different features in an (unregularized) Logistic Regression fit. StatsModels suggests (based off of large p-values) that the most influential variables are (1) whether the event occured on the first Sunday, (2) the words/sentence, and (3) whether the event was on Saturday, and (4) the overall sentence count. Several other variables appear prominently, while the majority have negligible p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ystats = y_train['Class/Workshop']\n",
    "Xstats = pd.DataFrame(X_train.toarray(), columns=[features + days + basic_features])\n",
    "Xstats['target'] = ystats.values\n",
    "\n",
    "print(np.shape(ystats))\n",
    "print(np.shape(Xstats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = dm.Logit(Xstats['target'], Xstats[all_feature_names[0]])\n",
    "\n",
    "result = lr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1214: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1264: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                10082\n",
      "Model:                          Logit   Df Residuals:                    10042\n",
      "Method:                           MLE   Df Model:                           39\n",
      "Date:                Thu, 17 May 2018   Pseudo R-squ.:                    -inf\n",
      "Time:                        22:55:36   Log-Likelihood:                   -inf\n",
      "converged:                       True   LL-Null:                   -1.3385e+06\n",
      "                                        LLR p-value:                     1.000\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "uppercase_freq             -5.4078      0.923     -5.858      0.000      -7.217      -3.599\n",
      "sentence_count              0.0066      0.012      0.543      0.587      -0.017       0.031\n",
      "word_count                 -0.0931      0.013     -7.338      0.000      -0.118      -0.068\n",
      "unique_word_count           0.0156      0.009      1.819      0.069      -0.001       0.032\n",
      "count_letters               0.0088      0.002      5.453      0.000       0.006       0.012\n",
      "count_punctuations          0.0063      0.009      0.689      0.491      -0.012       0.024\n",
      "count_words_title          -0.0130      0.006     -2.105      0.035      -0.025      -0.001\n",
      "count_stopwords             0.0758      0.009      8.425      0.000       0.058       0.093\n",
      "mean_word_len               0.5372      0.080      6.747      0.000       0.381       0.693\n",
      "count_kids_words           -0.1765      0.223     -0.793      0.428      -0.613       0.260\n",
      "count_party_words          -0.3288      0.038     -8.670      0.000      -0.403      -0.254\n",
      "count_adult_words          -0.3061      0.052     -5.856      0.000      -0.408      -0.204\n",
      "count_game_words           -0.3082      0.042     -7.269      0.000      -0.391      -0.225\n",
      "count_ritual_words         -0.0898      0.067     -1.332      0.183      -0.222       0.042\n",
      "count_care_words            0.3363      0.044      7.631      0.000       0.250       0.423\n",
      "count_class_words           0.9219      0.050     18.327      0.000       0.823       1.020\n",
      "count_performance_words    -0.3567      0.054     -6.627      0.000      -0.462      -0.251\n",
      "count_food_words           -0.7030      0.064    -10.917      0.000      -0.829      -0.577\n",
      "count_fire_words           -0.1346      0.041     -3.318      0.001      -0.214      -0.055\n",
      "count_parade_words         -0.5016      0.167     -3.008      0.003      -0.828      -0.175\n",
      "unique_word_ratio           1.3625      0.513      2.658      0.008       0.358       2.367\n",
      "percent_ratio              -2.5299      0.493     -5.134      0.000      -3.496      -1.564\n",
      "words_per_sentence         -0.0003      0.002     -0.218      0.828      -0.003       0.003\n",
      "sentiment_compound         -0.0816      0.120     -0.682      0.496      -0.316       0.153\n",
      "sentiment_negative         -5.6737      0.833     -6.813      0.000      -7.306      -4.041\n",
      "sentiment_positive         -3.9129      0.751     -5.208      0.000      -5.385      -2.440\n",
      "sentiment_neutral          -3.4787      0.599     -5.812      0.000      -4.652      -2.306\n",
      "Sunday                     -0.0018      0.218     -0.008      0.993      -0.429       0.425\n",
      "Monday                     -0.2336      0.073     -3.206      0.001      -0.376      -0.091\n",
      "Tuesday                     0.0571      0.057      1.002      0.316      -0.055       0.169\n",
      "Wednesday                  -0.0648      0.054     -1.197      0.231      -0.171       0.041\n",
      "Thursday                   -0.2638      0.055     -4.783      0.000      -0.372      -0.156\n",
      "Friday                     -0.2145      0.059     -3.638      0.000      -0.330      -0.099\n",
      "Saturday                    0.0368      0.080      0.461      0.645      -0.120       0.194\n",
      "Sunday2                    -0.6253      0.151     -4.129      0.000      -0.922      -0.328\n",
      "Monday2                    -0.2796      0.314     -0.890      0.374      -0.896       0.336\n",
      "Contact Email              -0.0584      0.054     -1.083      0.279      -0.164       0.047\n",
      "URL                        -0.3806      0.054     -7.024      0.000      -0.487      -0.274\n",
      "Located at Art              1.0128      0.232      4.373      0.000       0.559       1.467\n",
      "Event Length               -0.1374      0.009    -14.543      0.000      -0.156      -0.119\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tfidf'></a>\n",
    "\n",
    "# With TF-IDF Vectorization\n",
    "\n",
    "Now let's include more complex TF-IDF Bag of Words type features to see how much that improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20165, 3097)\n"
     ]
    }
   ],
   "source": [
    "count_vect_desc  = CountVectorizer(stop_words='english', min_df=40,  ngram_range=(1, 3), analyzer='word')\n",
    "\n",
    "X = count_vect_desc.fit_transform(events['Description'].values);\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "X = transformer.fit_transform(X)\n",
    "\n",
    "iX_desc  = X.shape[1]\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20165, 3137)\n"
     ]
    }
   ],
   "source": [
    "basic_features = ['Contact Email', 'URL', 'Located at Art', 'Event Length']\n",
    "\n",
    "desc_length = shape(X)[1]\n",
    "\n",
    "print(shape(X));\n",
    "print(shape(events[days].values));\n",
    "print(shape(events[basic_features].values));\n",
    "\n",
    "all_feature_names = ['str('+name+')' for name in count_vect_desc.get_feature_names()] + features + days + basic_features\n",
    "\n",
    "X = sparse.csr_matrix(hstack((X.toarray(), X_handFeatures, events[days].values, events[basic_features].values)))\n",
    "\n",
    "print(shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10082, 3137)\n",
      "(10083, 3137)\n",
      "(10082, 12)\n",
      "(10083, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, types_test, test_size=0.5, stratify=types_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including text features helps even more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:10<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "types_pred = y_test.copy()\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for name in tqdm(type_names):\n",
    "    clf = LogisticRegression().fit(X_train, y_train[name])\n",
    "    \n",
    "    types_pred[name] = clf.predict(X_test)\n",
    "    \n",
    "    classifiers.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.62457459237169\n",
      "Std Dev ROC-AUC: 0.0949513392850482\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(y_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC-AUC is now all the way up to 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:10<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "types_pred = y_test.copy()\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for name in tqdm(type_names):\n",
    "    clf = LogisticRegression().fit(X_train, y_train[name])\n",
    "    \n",
    "    types_pred[name] = 1-clf.predict_proba(X_test)\n",
    "    \n",
    "    classifiers.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.8679557634221976\n",
      "Std Dev ROC-AUC: 0.06612030338248001\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(y_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
