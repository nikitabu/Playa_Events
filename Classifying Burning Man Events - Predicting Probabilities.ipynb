{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Burning Man Events Data: Predicting Probabilities\n",
    "\n",
    "In the previous classification approach we considered events to be exclusive a single type, with Precision, Recall, and F1 score as classification metrics. But, this may not necessarily be the case in practice. An event could be both a party and a food event for example. This possibility was made more evident upon analyzing the types of errors being made by the classifiers. Certain types of mislabels were common.\n",
    "\n",
    "Alternatively, we can instead predict the non-exclusive probability that event be categorized into a given type, and use a metric like ROC-AUC to gauge classifier performance.\n",
    "\n",
    "We'll start off the same as before, establishing baselines one step at a time. Totally random, or even weighted random, guessing gives a ROC-AUC of 0.5, corresponding to useful distinction between positive and negative labels. A simple rule-based system, just like the one used previously, but this time allowing for multiple positives, gives an average ROC-AUC of 0.65 with a standard deviation of 0.08. A noticable improvement. Adding more compex features along with logistic regression improves the ROC-AUC up to almost 0.80. And including word vectors brings this up even higher towards 0.87! A 0-1 prediction mechanism on the other hand only gives a ROC-AUC of 0.65.\n",
    "\n",
    "tl;dr Burning Man Org should consider allowing events to have multiple labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import seaborn as sns;\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "import string, nltk, re, pprint\n",
    "\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "from pylab import *;\n",
    "from scipy import sparse\n",
    "from time import time\n",
    "\n",
    "from nltk.corpus   import stopwords\n",
    "from nltk          import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error, mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import lightgbm as lgb;\n",
    "\n",
    "import random\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv('raw_data/cleaned_up.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_test = pd.get_dummies(events['Type'])\n",
    "\n",
    "events = events.drop(['Type'], axis=1)\n",
    "\n",
    "type_names = types_test.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Totally Random Guessing\n",
    "\n",
    "Random guessing gives a ROC-AUC score of 0.5, corresponding to no seperation between positive/negative predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 20165/20165 [00:44<00:00, 455.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adult-oriented</th>\n",
       "      <th>Care/Support</th>\n",
       "      <th>Class/Workshop</th>\n",
       "      <th>Fire</th>\n",
       "      <th>Food</th>\n",
       "      <th>Game</th>\n",
       "      <th>Gathering/Party</th>\n",
       "      <th>Kid-friendly</th>\n",
       "      <th>Other</th>\n",
       "      <th>Parade</th>\n",
       "      <th>Performance</th>\n",
       "      <th>Ritual/Ceremony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118623</td>\n",
       "      <td>0.537303</td>\n",
       "      <td>0.364735</td>\n",
       "      <td>0.775733</td>\n",
       "      <td>0.601314</td>\n",
       "      <td>0.349279</td>\n",
       "      <td>0.667272</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>0.784316</td>\n",
       "      <td>0.639475</td>\n",
       "      <td>0.693369</td>\n",
       "      <td>0.760332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.424644</td>\n",
       "      <td>0.493843</td>\n",
       "      <td>0.665252</td>\n",
       "      <td>0.256842</td>\n",
       "      <td>0.157670</td>\n",
       "      <td>0.206831</td>\n",
       "      <td>0.553095</td>\n",
       "      <td>0.572399</td>\n",
       "      <td>0.864926</td>\n",
       "      <td>0.865857</td>\n",
       "      <td>0.280772</td>\n",
       "      <td>0.071747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.335658</td>\n",
       "      <td>0.902867</td>\n",
       "      <td>0.683191</td>\n",
       "      <td>0.346968</td>\n",
       "      <td>0.847768</td>\n",
       "      <td>0.832887</td>\n",
       "      <td>0.281567</td>\n",
       "      <td>0.096269</td>\n",
       "      <td>0.395318</td>\n",
       "      <td>0.457716</td>\n",
       "      <td>0.140025</td>\n",
       "      <td>0.023011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.519150</td>\n",
       "      <td>0.394444</td>\n",
       "      <td>0.311601</td>\n",
       "      <td>0.402436</td>\n",
       "      <td>0.815058</td>\n",
       "      <td>0.683598</td>\n",
       "      <td>0.949927</td>\n",
       "      <td>0.703114</td>\n",
       "      <td>0.396114</td>\n",
       "      <td>0.375225</td>\n",
       "      <td>0.759439</td>\n",
       "      <td>0.498826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.603419</td>\n",
       "      <td>0.482301</td>\n",
       "      <td>0.633055</td>\n",
       "      <td>0.853336</td>\n",
       "      <td>0.236696</td>\n",
       "      <td>0.334075</td>\n",
       "      <td>0.098722</td>\n",
       "      <td>0.759311</td>\n",
       "      <td>0.615169</td>\n",
       "      <td>0.557182</td>\n",
       "      <td>0.335717</td>\n",
       "      <td>0.245093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adult-oriented  Care/Support  Class/Workshop      Fire      Food      Game  \\\n",
       "0        0.118623      0.537303        0.364735  0.775733  0.601314  0.349279   \n",
       "1        0.424644      0.493843        0.665252  0.256842  0.157670  0.206831   \n",
       "2        0.335658      0.902867        0.683191  0.346968  0.847768  0.832887   \n",
       "3        0.519150      0.394444        0.311601  0.402436  0.815058  0.683598   \n",
       "4        0.603419      0.482301        0.633055  0.853336  0.236696  0.334075   \n",
       "\n",
       "   Gathering/Party  Kid-friendly     Other    Parade  Performance  \\\n",
       "0         0.667272      0.046048  0.784316  0.639475     0.693369   \n",
       "1         0.553095      0.572399  0.864926  0.865857     0.280772   \n",
       "2         0.281567      0.096269  0.395318  0.457716     0.140025   \n",
       "3         0.949927      0.703114  0.396114  0.375225     0.759439   \n",
       "4         0.098722      0.759311  0.615169  0.557182     0.335717   \n",
       "\n",
       "   Ritual/Ceremony  \n",
       "0         0.760332  \n",
       "1         0.071747  \n",
       "2         0.023011  \n",
       "3         0.498826  \n",
       "4         0.245093  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_pred = pd.DataFrame(columns=type_names)\n",
    "\n",
    "for i in tqdm(range(len(types_test))):\n",
    "    types_pred = types_pred.append({name:random.uniform(0, 1) for name in type_names}, ignore_index=True)\n",
    "\n",
    "types_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.49593694351676354\n",
      "Std Dev ROC-AUC: 0.008949933671384422\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(types_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighed by prior event distributions, the average ROC-AUC is exactly 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 20165/20165 [00:44<00:00, 450.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adult-oriented</th>\n",
       "      <th>Care/Support</th>\n",
       "      <th>Class/Workshop</th>\n",
       "      <th>Fire</th>\n",
       "      <th>Food</th>\n",
       "      <th>Game</th>\n",
       "      <th>Gathering/Party</th>\n",
       "      <th>Kid-friendly</th>\n",
       "      <th>Other</th>\n",
       "      <th>Parade</th>\n",
       "      <th>Performance</th>\n",
       "      <th>Ritual/Ceremony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05574</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.318324</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.041557</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.261939</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.070469</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.077213</td>\n",
       "      <td>0.05088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05574</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.318324</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.041557</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.261939</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.070469</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.077213</td>\n",
       "      <td>0.05088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05574</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.318324</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.041557</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.261939</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.070469</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.077213</td>\n",
       "      <td>0.05088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05574</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.318324</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.041557</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.261939</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.070469</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.077213</td>\n",
       "      <td>0.05088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05574</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.318324</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.041557</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.261939</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.070469</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.077213</td>\n",
       "      <td>0.05088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adult-oriented  Care/Support  Class/Workshop      Fire      Food      Game  \\\n",
       "0         0.05574      0.036896        0.318324  0.008034  0.041557  0.047012   \n",
       "1         0.05574      0.036896        0.318324  0.008034  0.041557  0.047012   \n",
       "2         0.05574      0.036896        0.318324  0.008034  0.041557  0.047012   \n",
       "3         0.05574      0.036896        0.318324  0.008034  0.041557  0.047012   \n",
       "4         0.05574      0.036896        0.318324  0.008034  0.041557  0.047012   \n",
       "\n",
       "   Gathering/Party  Kid-friendly     Other    Parade  Performance  \\\n",
       "0         0.261939      0.018001  0.070469  0.013935     0.077213   \n",
       "1         0.261939      0.018001  0.070469  0.013935     0.077213   \n",
       "2         0.261939      0.018001  0.070469  0.013935     0.077213   \n",
       "3         0.261939      0.018001  0.070469  0.013935     0.077213   \n",
       "4         0.261939      0.018001  0.070469  0.013935     0.077213   \n",
       "\n",
       "   Ritual/Ceremony  \n",
       "0          0.05088  \n",
       "1          0.05088  \n",
       "2          0.05088  \n",
       "3          0.05088  \n",
       "4          0.05088  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_pred = pd.DataFrame(columns=type_names)\n",
    "\n",
    "p = types_test.sum().values/types_test.sum().values.sum()\n",
    "\n",
    "for i in tqdm(range(len(types_test))):\n",
    "    types_pred = types_pred.append({name:p[i] for i, name in enumerate(type_names)}, ignore_index=True)\n",
    "\n",
    "types_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.5\n",
      "Std Dev ROC-AUC: 0.0\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(types_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Rule-Based Classification\n",
    "\n",
    "Let's see what accuracy we can achieve using an extremely simple rule-based classification scheme, based on findings from the Exploratory Data Analysis.\n",
    "\n",
    "This simple rule system brings the ROC-AUC up to 0.65, with a standard-deviation of 0.08. So we did get a noticable improvement over random guessing with this sytem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events[\"Description\"] = (events[\"Description\"].map(str) + ' ' + \n",
    "                         events[\"Title\"].map(str) + ' ' + \n",
    "                         events[\"Hosted by Camp\"].map(str) + ' ' + \n",
    "                         events[\"Location\"].map(str))\n",
    "\n",
    "events = events.drop(['Title', 'Hosted by Camp', 'Location'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_words  = ['adult', 'massage', 'sensual', 'erotic', 'sex', 'bdsm', 'pleasure']\n",
    "care_words   = ['heal', 'massage', 'help', 'body']\n",
    "class_words  = ['learn', 'workshop', 'practice', 'class']\n",
    "fire_words   = ['fire', 'burn', 'spin', 'fuel', 'flame', 'light', 'flow']\n",
    "food_words   = ['coffee', 'pickle', 'food', 'serv', 'fresh', 'bacon', 'cheese', 'delicious', 'pancake', 'tast']\n",
    "game_words   = ['game', 'play', 'prize', 'race', 'tournament']\n",
    "party_words  = ['party', 'dance', 'music', 'celebrate']\n",
    "kids_words   = ['kid', 'scout']\n",
    "parade_words = ['parade', 'march', 'tour']\n",
    "perfor_words = ['perform', 'stage', 'live', 'show', 'audience']\n",
    "ritual_words = ['ceremony', 'ritual', 'temple', 'sacred']\n",
    "\n",
    "words = {'Adult-oriented': adult_words,\n",
    "         'Care/Support':care_words,\n",
    "         'Class/Workshop':class_words,\n",
    "         'Fire':fire_words,\n",
    "         'Food':food_words,\n",
    "         'Game':game_words,\n",
    "         'Gathering/Party':party_words,\n",
    "         'Kid-friendly':kids_words,\n",
    "         'Parade':parade_words,\n",
    "         'Performance':perfor_words,\n",
    "         'Ritual/Ceremony':ritual_words,\n",
    "         'Other':[]}\n",
    "\n",
    "def simple_classify(desc, words):\n",
    "    return any([word in desc for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 20165/20165 [01:19<00:00, 254.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adult-oriented</th>\n",
       "      <th>Care/Support</th>\n",
       "      <th>Class/Workshop</th>\n",
       "      <th>Fire</th>\n",
       "      <th>Food</th>\n",
       "      <th>Game</th>\n",
       "      <th>Gathering/Party</th>\n",
       "      <th>Kid-friendly</th>\n",
       "      <th>Other</th>\n",
       "      <th>Parade</th>\n",
       "      <th>Performance</th>\n",
       "      <th>Ritual/Ceremony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Adult-oriented Care/Support Class/Workshop   Fire   Food   Game  \\\n",
       "0          False        False          False   True  False  False   \n",
       "1          False        False          False  False  False  False   \n",
       "2          False        False          False  False  False  False   \n",
       "3          False        False          False  False  False  False   \n",
       "4          False        False          False  False  False  False   \n",
       "\n",
       "  Gathering/Party Kid-friendly  Other Parade Performance Ritual/Ceremony  \n",
       "0           False        False  False  False       False           False  \n",
       "1           False        False  False  False       False           False  \n",
       "2           False        False  False  False       False           False  \n",
       "3           False        False  False  False       False           False  \n",
       "4           False        False  False  False       False           False  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_pred = pd.DataFrame(columns=type_names)\n",
    "\n",
    "descriptions = events['Description'].values\n",
    "\n",
    "for desc in tqdm(descriptions):\n",
    "    types_pred = types_pred.append({name:simple_classify(desc, words[name]) for name in type_names}, ignore_index=True)\n",
    "        \n",
    "types_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.6527309204301003\n",
      "Std Dev ROC-AUC: 0.08677021943808555\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(types_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Complex Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 839743.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 207526.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 102644.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 91066.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 109337.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 123187.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 229153.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 503738.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 20165/20165 [00:00<00:00, 1005565.81it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_12_to_24(time):\n",
    "    if 'a.m.' in time:\n",
    "        time = time.replace(' a.m.', '')\n",
    "        if ':' not in time:\n",
    "            time = time + ':00'    \n",
    "    elif 'p.m.' in time:\n",
    "        time = time.replace(' p.m.', '')\n",
    "        if ':' not in time:\n",
    "            if '12' in time:\n",
    "                time = time + ':00'\n",
    "            else:\n",
    "                time = str(int(time)+12) + ':00'\n",
    "        elif '12' in time:\n",
    "            pass\n",
    "        else:\n",
    "            time_split = time.split(':')\n",
    "            time = str(int(time_split[0])+12) + ':' + time_split[1]\n",
    "    elif 'midnight' in time:\n",
    "        time = '23:45'\n",
    "    elif 'noon' in time:\n",
    "        time = '12:00'\n",
    "            \n",
    "    return time\n",
    "\n",
    "def get_time_diff(df):      \n",
    "    times = [];\n",
    "\n",
    "    for row in tqdm(df.values): \n",
    "        if row == '0':\n",
    "            times.append(np.nan);\n",
    "        elif row == 'All Day':\n",
    "            times.append((datetime.datetime.strptime('23:59', '%H:%M')-datetime.datetime.strptime('00:00', '%H:%M')).total_seconds()/3600)\n",
    "        else:\n",
    "            split = row.split(' – ');\n",
    "            \n",
    "            split[0] = convert_12_to_24(split[0])\n",
    "            split[1] = convert_12_to_24(split[1])\n",
    "\n",
    "            times.append((datetime.datetime.strptime(split[1], '%H:%M')-datetime.datetime.strptime(split[0], '%H:%M')).total_seconds()/3600)\n",
    "    \n",
    "    return times;\n",
    "\n",
    "times_1 = pd.DataFrame(get_time_diff(events['Sunday']),    columns=['Event Length'])\n",
    "times_2 = pd.DataFrame(get_time_diff(events['Monday']),    columns=['Event Length'])\n",
    "times_3 = pd.DataFrame(get_time_diff(events['Tuesday']),   columns=['Event Length'])\n",
    "times_4 = pd.DataFrame(get_time_diff(events['Wednesday']), columns=['Event Length'])\n",
    "times_5 = pd.DataFrame(get_time_diff(events['Thursday']),  columns=['Event Length'])\n",
    "times_6 = pd.DataFrame(get_time_diff(events['Friday']),    columns=['Event Length'])\n",
    "times_7 = pd.DataFrame(get_time_diff(events['Saturday']),  columns=['Event Length'])\n",
    "times_8 = pd.DataFrame(get_time_diff(events['Sunday2']),   columns=['Event Length'])\n",
    "times_9 = pd.DataFrame(get_time_diff(events['Monday2']),   columns=['Event Length'])\n",
    "\n",
    "times = times_1.fillna(times_2).fillna(times_3).fillna(times_4).fillna(times_5).fillna(times_6).fillna(times_7).fillna(times_8).fillna(times_9)\n",
    "\n",
    "events['Event Length'] = abs(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert Days to Simple Binary (Lose Time of Day Information)\n",
    "\n",
    "days = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday2', 'Monday2'];\n",
    "\n",
    "events[days] = ((events[days] == '0') == False).astype(int);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['Times Repeated'] = 0\n",
    "\n",
    "for day in days:\n",
    "    events['Times Repeated'] += events[day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert Contact Email, URL to Binary\n",
    "\n",
    "events['Contact Email']  = pd.isnull(events['Contact Email']).values.astype(int)\n",
    "events['URL']            = pd.isnull(events['URL']).values.astype(int)\n",
    "events['Located at Art'] = pd.isnull(events['Located at Art']).values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first build a classifier with simple engineered features (no TF-IDF) and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# FEATURE ENGINEERING #\n",
    "#######################\n",
    "\n",
    "def engineer_feature(series, func, normalize=True):\n",
    "    feature = series.apply(func)\n",
    "       \n",
    "    if normalize:\n",
    "        feature = pd.Series(z_normalize(feature.values.reshape(-1,1)).reshape(-1,))\n",
    "    feature.name = func.__name__ \n",
    "    return feature\n",
    "\n",
    "def engineer_features(series, funclist, normalize=True):\n",
    "    features = pd.DataFrame()\n",
    "    for func in funclist:\n",
    "        print(str(func))\n",
    "        feature = engineer_feature(series, func, normalize)\n",
    "        features[feature.name] = feature\n",
    "    return features\n",
    "\n",
    "##################\n",
    "### Normalizer ###\n",
    "##################\n",
    "\n",
    "scaler = StandardScaler()\n",
    "def z_normalize(data):\n",
    "    scaler.fit(data)\n",
    "    return scaler.transform(data)\n",
    "    \n",
    "def count_words(x, words):\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        count += len(re.findall(word, str(x)))\n",
    "    return count\n",
    "    \n",
    "################\n",
    "### Features ###\n",
    "################\n",
    "\n",
    "def uppercase_freq(x):\n",
    "    return len(re.findall(r'[A-Z]', x))/len(x)\n",
    "\n",
    "def sentence_count(x):\n",
    "    return len(re.findall(\"\\n\", str(x)))+1\n",
    "\n",
    "def word_count(x):\n",
    "    return len(str(x).split())\n",
    "\n",
    "def unique_word_count(x):\n",
    "    return len(set(str(x).split()))\n",
    "\n",
    "def count_letters(x):\n",
    "    return len(str(x))\n",
    "\n",
    "def count_punctuations(x):\n",
    "    return len([c for c in str(x) if c in string.punctuation])\n",
    "\n",
    "def count_words_title(x):\n",
    "    return len([w for w in str(x).split() if w.istitle()])\n",
    "\n",
    "def count_stopwords(x):\n",
    "    return len([w for w in str(x).lower().split() if w in eng_stopwords])\n",
    "\n",
    "def mean_word_len(x):\n",
    "    words = [len(w) for w in str(x).split()]\n",
    "\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.mean(words)\n",
    "\n",
    "##################################\n",
    "### Category-Specific Features ###\n",
    "##################################\n",
    "\n",
    "def count_kids_words(x):\n",
    "    return count_words(x, ['kid', 'scout'])\n",
    "\n",
    "def count_party_words(x):\n",
    "    return count_words(x, ['party', 'dance', 'music', 'celebrate'])\n",
    "\n",
    "def count_adult_words(x):\n",
    "    return count_words(x, ['adult', 'massage', 'sensual', 'erotic', 'sex', 'bdsm', 'pleasure'])\n",
    "\n",
    "def count_game_words(x):\n",
    "    return count_words(x, ['game', 'play', 'prize', 'race', 'tournament'])\n",
    "\n",
    "def count_ritual_words(x):\n",
    "    return count_words(x, ['ceremony', 'ritual', 'temple', 'sacred'])\n",
    "    \n",
    "def count_care_words(x):\n",
    "    return count_words(x, ['heal', 'massage', 'help', 'body'])\n",
    "\n",
    "def count_class_words(x):\n",
    "    return count_words(x, ['learn', 'workshop', 'practice', 'class'])\n",
    "\n",
    "def count_performance_words(x):\n",
    "    return count_words(x, ['perform', 'stage', 'live', 'show', 'audience'])\n",
    "\n",
    "def count_food_words(x):\n",
    "    return count_words(x, ['coffee', 'pickle', 'food', 'serv', 'fresh', 'bacon', 'cheese', 'delicious', 'pancake', 'tast'])\n",
    "\n",
    "def count_fire_words(x):\n",
    "    return count_words(x, ['fire', 'burn', 'spin', 'fuel', 'flame', 'light', 'flow'])\n",
    "\n",
    "def count_parade_words(x):\n",
    "    return count_words(x, ['parade', 'march', 'tour'])\n",
    "\n",
    "############################\n",
    "### Sentimental Features ###\n",
    "############################\n",
    "\n",
    "sia = SIA();\n",
    "\n",
    "def sentiment_compound(x):\n",
    "    polarity = sia.polarity_scores(x)\n",
    "    return polarity['compound']       \n",
    "\n",
    "def sentiment_negative(x):\n",
    "    polarity = sia.polarity_scores(x)\n",
    "    return polarity['neg']       \n",
    "\n",
    "def sentiment_neutral(x):\n",
    "    polarity = sia.polarity_scores(x)\n",
    "    return polarity['neu']       \n",
    "\n",
    "def sentiment_positive(x):\n",
    "    polarity = sia.polarity_scores(x)\n",
    "    return polarity['pos']       \n",
    "        \n",
    "########################\n",
    "### Derived Features ###\n",
    "########################\n",
    "\n",
    "def unique_word_ratio(x):\n",
    "    wc = word_count(x)\n",
    "    \n",
    "    if wc == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return unique_word_count(x)/wc\n",
    "\n",
    "def percent_ratio(x):\n",
    "    wc = word_count(x)\n",
    "    \n",
    "    if wc == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return count_punctuations(x)/wc\n",
    "\n",
    "def words_per_sentence(x):\n",
    "    sc = sentence_count(x)\n",
    "    \n",
    "    if sc == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return word_count(x)/sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function uppercase_freq at 0x000001E59FC240D0>\n",
      "<function sentence_count at 0x000001E59FC24158>\n",
      "<function word_count at 0x000001E59FC24950>\n",
      "<function unique_word_count at 0x000001E59FC24A60>\n",
      "<function count_letters at 0x000001E59FC248C8>\n",
      "<function count_punctuations at 0x000001E59FC249D8>\n",
      "<function count_words_title at 0x000001E59FC24AE8>\n",
      "<function count_stopwords at 0x000001E59FC24BF8>\n",
      "<function mean_word_len at 0x000001E59FC24B70>\n",
      "<function count_kids_words at 0x000001E59FC24D90>\n",
      "<function count_party_words at 0x000001E59FC24C80>\n",
      "<function count_adult_words at 0x000001E59FC24D08>\n",
      "<function count_game_words at 0x000001E59FC24F28>\n",
      "<function count_ritual_words at 0x000001E59FC24E18>\n",
      "<function count_care_words at 0x000001E59FC24EA0>\n",
      "<function count_class_words at 0x000001E59C68A730>\n",
      "<function count_performance_words at 0x000001E59C68AB70>\n",
      "<function count_food_words at 0x000001E59C68A9D8>\n",
      "<function count_fire_words at 0x000001E59C68ABF8>\n",
      "<function count_parade_words at 0x000001E59C68A1E0>\n",
      "<function unique_word_ratio at 0x000001E59C68A488>\n",
      "<function percent_ratio at 0x000001E59C68AD90>\n",
      "<function words_per_sentence at 0x000001E59C68AAE8>\n",
      "<function sentiment_compound at 0x000001E5EE8F0158>\n",
      "<function sentiment_negative at 0x000001E59C68A8C8>\n",
      "<function sentiment_positive at 0x000001E59C68AF28>\n",
      "<function sentiment_neutral at 0x000001E59C68AD08>\n"
     ]
    }
   ],
   "source": [
    "feature_functions = [uppercase_freq, sentence_count, word_count, unique_word_count, count_letters, count_punctuations, \n",
    "                     count_words_title, count_stopwords, mean_word_len, count_kids_words, count_party_words, \n",
    "                     count_adult_words, count_game_words, count_ritual_words, count_care_words,\n",
    "                     count_class_words, count_performance_words, count_food_words, count_fire_words, count_parade_words,\n",
    "                     unique_word_ratio, percent_ratio, words_per_sentence,\n",
    "                     sentiment_compound, sentiment_negative, sentiment_positive, sentiment_neutral]\n",
    "\n",
    "features = [f.__name__ for f in feature_functions]\n",
    "\n",
    "F_train = engineer_features(events['Description'].fillna(''), feature_functions, normalize=False)\n",
    "\n",
    "X_handFeatures = F_train[features].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20165, 40)\n"
     ]
    }
   ],
   "source": [
    "basic_features = ['Contact Email', 'URL', 'Located at Art', 'Event Length']\n",
    "\n",
    "X = sparse.csr_matrix(hstack((X_handFeatures, events[days].values, events[basic_features].values)))\n",
    "\n",
    "print(shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adult-oriented</th>\n",
       "      <th>Care/Support</th>\n",
       "      <th>Class/Workshop</th>\n",
       "      <th>Fire</th>\n",
       "      <th>Food</th>\n",
       "      <th>Game</th>\n",
       "      <th>Gathering/Party</th>\n",
       "      <th>Kid-friendly</th>\n",
       "      <th>Other</th>\n",
       "      <th>Parade</th>\n",
       "      <th>Performance</th>\n",
       "      <th>Ritual/Ceremony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adult-oriented  Care/Support  Class/Workshop  Fire  Food  Game  \\\n",
       "0               0             0               0     0     0     0   \n",
       "1               0             0               0     0     0     0   \n",
       "2               0             0               0     0     0     0   \n",
       "3               0             0               0     0     0     0   \n",
       "4               0             0               0     0     0     1   \n",
       "\n",
       "   Gathering/Party  Kid-friendly  Other  Parade  Performance  Ritual/Ceremony  \n",
       "0                0             0      1       0            0                0  \n",
       "1                0             1      0       0            0                0  \n",
       "2                0             1      0       0            0                0  \n",
       "3                1             0      0       0            0                0  \n",
       "4                0             0      0       0            0                0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10082, 40)\n",
      "(10083, 40)\n",
      "(10082, 12)\n",
      "(10083, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, types_test, test_size=0.5, stratify=types_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting 0,1 probablities give an ROC-AUC only a little better than random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.74it/s]\n"
     ]
    }
   ],
   "source": [
    "types_pred = y_test.copy()\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for name in tqdm(type_names):\n",
    "    clf = LogisticRegression().fit(X_train, y_train[name])\n",
    "    \n",
    "    types_pred[name] = clf.predict(X_test)\n",
    "    \n",
    "    classifiers.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.5627325728279179\n",
      "Std Dev ROC-AUC: 0.05981430712187226\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(y_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas predicting the probabilities of each class shoots the average ROC-AUC all the way up to almost 0.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.90it/s]\n"
     ]
    }
   ],
   "source": [
    "types_pred = y_test.copy()\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for name in tqdm(type_names):\n",
    "    clf = LogisticRegression().fit(X_train, y_train[name])\n",
    "    \n",
    "    types_pred[name] = 1-clf.predict_proba(X_test) # not sure why sklearn is outputting the wrong (1-p) probability\n",
    "    \n",
    "    classifiers.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.7951847309055863\n",
      "Std Dev ROC-AUC: 0.06622114708620694\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(y_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7760055408516331,\n",
       " 0.7967176121082068,\n",
       " 0.8301661927819953,\n",
       " 0.9361769621384366,\n",
       " 0.8513335667941646,\n",
       " 0.8028762152921861,\n",
       " 0.7818693771273311,\n",
       " 0.7767552958217047,\n",
       " 0.644613740063018,\n",
       " 0.8341532449246419,\n",
       " 0.7636766717035863,\n",
       " 0.7478723512601311]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With TF-IDF Vectorization\n",
    "\n",
    "Now let's include more complex TF-IDF Bag of Words type features to see how much that improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the CountVectorizer on the event descriptions and event titles\n",
    "'''\n",
    "count_vect_desc  = CountVectorizer(stop_words='english', min_df=25,  ngram_range=(1, 3), analyzer='word')\n",
    "count_vect_title = CountVectorizer(stop_words='english', min_df=25,  ngram_range=(1, 3), analyzer='word')\n",
    "count_vect_camp  = CountVectorizer(stop_words='english', min_df=100, ngram_range=(3, 5), analyzer='char')\n",
    "count_vect_loca  = CountVectorizer(stop_words='english', min_df=50,  ngram_range=(3, 5), analyzer='char')\n",
    "\n",
    "X        = count_vect_desc.fit_transform(events['Description'].values);\n",
    "X_titles = count_vect_title.fit_transform(events['Title'].values);\n",
    "X_camp   = count_vect_camp.fit_transform([str(event) for event in events['Hosted by Camp'].fillna('').values]);\n",
    "X_loca   = count_vect_camp.fit_transform([str(event) for event in events['Location'].fillna('').values]);\n",
    "\n",
    "iX_desc  = X.shape[1]\n",
    "iX_title = X_titles.shape[1]\n",
    "iX_camp  = X_camp.shape[1]\n",
    "iX_loca  = X_loca.shape[1]\n",
    "\n",
    "print(X.shape)\n",
    "print(X_titles.shape)\n",
    "print(X_camp.shape)\n",
    "print(X_loca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20165, 2483)\n"
     ]
    }
   ],
   "source": [
    "count_vect_desc  = CountVectorizer(stop_words='english', min_df=40,  ngram_range=(1, 3), analyzer='word')\n",
    "\n",
    "X = count_vect_desc.fit_transform(events['Description'].values);\n",
    "\n",
    "iX_desc  = X.shape[1]\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20165, 2483)\n",
      "(20165, 9)\n",
      "(20165, 4)\n"
     ]
    }
   ],
   "source": [
    "basic_features = ['Contact Email', 'URL', 'Located at Art', 'Event Length']\n",
    "\n",
    "print(shape(X));\n",
    "#print(shape(X_titles));\n",
    "#print(shape(X_camp));\n",
    "print(shape(events[days].values));\n",
    "print(shape(events[basic_features].values));\n",
    "\n",
    "desc_length = shape(X)[1]\n",
    "\n",
    "#print(desc_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "enc = OneHotEncoder()\n",
    "le  = LabelEncoder()\n",
    "\n",
    "camps = events['Hosted by Camp'].fillna('')\n",
    "\n",
    "events['Hosted by Camp'] = le.fit_transform(camps)\n",
    "\n",
    "camps = enc.fit_transform(events[['Hosted by Camp']])\n",
    "\n",
    "camps.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20165, 2523)\n"
     ]
    }
   ],
   "source": [
    "#X = sparse.csr_matrix(hstack((X.toarray(), X_titles.toarray(), X_camp.toarray(), X_handFeatures, \n",
    "#                              events[days].values, events[basic_features].values)))\n",
    "\n",
    "#X = sparse.csr_matrix(hstack((X.toarray(), X_titles.toarray(), X_handFeatures, camps.toarray(), \n",
    "#                              events[days].values, events[basic_features].values)))\n",
    "\n",
    "X = sparse.csr_matrix(hstack((X.toarray(), X_handFeatures, events[days].values, events[basic_features].values)))\n",
    "\n",
    "print(shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_feature_names = ['str('+name+')' for name in count_vect_desc.get_feature_names()] + features + days + basic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10082, 2523)\n",
      "(10083, 2523)\n",
      "(10082, 12)\n",
      "(10083, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, types_test, test_size=0.5, stratify=types_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including text features helps even more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:10<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "types_pred = y_test.copy()\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for name in tqdm(type_names):\n",
    "    clf = LogisticRegression().fit(X_train, y_train[name])\n",
    "    \n",
    "    types_pred[name] = clf.predict(X_test)\n",
    "    \n",
    "    classifiers.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.6475713235895707\n",
      "Std Dev ROC-AUC: 0.083768452778656\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(y_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC-AUC is now all the way up to 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:10<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "types_pred = y_test.copy()\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for name in tqdm(type_names):\n",
    "    clf = LogisticRegression().fit(X_train, y_train[name])\n",
    "    \n",
    "    types_pred[name] = 1-clf.predict_proba(X_test)\n",
    "    \n",
    "    classifiers.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.8679557634221976\n",
      "Std Dev ROC-AUC: 0.06612030338248001\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name in type_names:\n",
    "    score = roc_auc_score(y_test[name], types_pred[name])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Average ROC-AUC: ' + str(np.mean(scores)))\n",
    "print('Std Dev ROC-AUC: ' + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
